{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahan-Daksh/sdgp-rag-chatbot-test/blob/main/UGC_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wluRUO9IMmcN",
        "outputId": "e6d92794-bdea-4dcc-e247-67ca062f836a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR-YqSdDNlR-",
        "outputId": "856e47c0-d30f-4468-da7e-77fa146bebd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.13.1\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "!pip install PyPDF2\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JeXN42_SenP",
        "outputId": "18a5a9f6-e763-45c6-ec76-4bbdd3392582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Query......Find details about university admissions for a candidate with the following criteria:  Z-Score: 1.7,   G.C.E. (Advanced Level) Subjects and Grades:   1. Physics - A,   2. Chemistry - A,   3. Biology - B,    Preferred Courses of Study: Medicine, Dental Surgery, Pharmacy,   District: Kandy.    List the eligible courses of study, minimum entry requirements, applicable cut-off marks, and any district quota information for the specified criteria. Include relevant details about preferred courses and universities that offer them.  give all are in a list  witch is in a table.\n",
            "\n",
            "Response from the model:\n",
            "Based on the provided criteria, here is the information about university admissions for a candidate from Kandy district with a Z-Score of 1.7 and G.C.E. (Advanced Level) subjects and grades:\n",
            "\n",
            "| Course of Study | Minimum Entry Requirements | Applicable Cut-off Marks | District Quota Information | Preferred Universities |\n",
            "| --- | --- | --- | --- | --- |\n",
            "| Medicine | Z-Score: 1.7 (not eligible) | Not applicable | Not applicable | University of Colombo, University of Peradeniya, University of Ruhuna |\n",
            "| Dental Surgery | Z-Score: 1.7 (not eligible) | Not applicable | Not applicable | University of Colombo, University of Peradeniya, University of Ruhuna |\n",
            "| Pharmacy | Z-Score: 1.7 (not eligible) | Not applicable | Not applicable | University of Colombo, University of Peradeniya, University of Ruhuna |\n",
            "\n",
            "Note: The candidate's Z-Score of 1.7 is not sufficient to meet the minimum entry requirements for Medicine, Dental Surgery, and Pharmacy courses, which typically require a Z-Score of 2.5 or higher.\n",
            "\n",
            "However, the candidate may consider other courses of study that have lower minimum entry requirements. Here are some options:\n",
            "\n",
            "| Course of Study | Minimum Entry Requirements | Applicable Cut-off Marks | District Quota Information | Preferred Universities |\n",
            "| --- | --- | --- | --- | --- |\n",
            "| Engineering Technology (ET) | Z-Score: 1.7 (eligible) | Not applicable | Not applicable | University of Kelaniya, University of Jaffna, University of Ruhuna, Rajarata University of Sri Lanka, Sabaragamuwa University of Sri Lanka, Wayamba University of Sri Lanka, Uva Wellassa University of Sri Lanka |\n",
            "| Biosystems Technology (BST) | Z-Score: 1.7 (eligible) | Not applicable | Not applicable | University of Colombo, University of Sri Jayewardenepura, University of Jaffna, University of Ruhuna, Eastern University, Sri Lanka, South Eastern University of Sri Lanka, Rajarata University of Sri Lanka |\n",
            "\n",
            "Note: The candidate's Z-Score of 1.7 meets the minimum entry requirements for Engineering Technology (ET) and Biosystems Technology (BST) courses.\n",
            "\n",
            "Please note that the information provided is based on the given criteria and may not be exhaustive. It is recommended to check with the universities and the University Grants\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#code 2\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import openai\n",
        "from groq import Groq\n",
        "\n",
        "# OpenAI API Key (Replace with your API key)\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "# Initialize Groq client\n",
        "# API Key for Groq\n",
        "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "# Step 1: Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Step 2: Split text into chunks\n",
        "def split_text_into_chunks(text, chunk_size=300):\n",
        "    words = text.split()\n",
        "    chunks = [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Step 3: Generate embeddings for chunks\n",
        "def generate_embeddings(text_chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(text_chunks)\n",
        "    return embeddings\n",
        "\n",
        "# Step 4: Store embeddings in FAISS\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 similarity\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "# Step 5: Retrieve relevant chunks\n",
        "def retrieve_relevant_chunks(query, text_chunks, index, model):\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, k=3)  # Retrieve top 3 matches\n",
        "    return [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "# Step 6: Query the language model\n",
        "def query_llm(client, query, context):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant answering questions based on provided context.\"},\n",
        "        {\"role\": \"assistant\", \"content\": context},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"llama3-8b-8192\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=512,\n",
        "        top_p=1,\n",
        "        stop=None,\n",
        "        stream=False,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Main Code\n",
        "pdf_path = \"/content/drive/MyDrive/UGC.pdf\"\n",
        "\n",
        "# Step 1: Extract text\n",
        "document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Step 2: Split into chunks\n",
        "text_chunks = split_text_into_chunks(document_text)\n",
        "\n",
        "# Step 3: Generate embeddings\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = generate_embeddings(text_chunks, model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Step 4: Create FAISS index\n",
        "faiss_index = create_faiss_index(np.array(embeddings))\n",
        "\n",
        "# Step 5: User Query\n",
        "user_query = input( \"Enteryour \")\n",
        "\n",
        "# Step 6: Retrieve relevant chunks\n",
        "relevant_chunks = retrieve_relevant_chunks(user_query, text_chunks, faiss_index, embedding_model)\n",
        "\n",
        "# Combine chunks into context\n",
        "context = \" \".join(relevant_chunks)\n",
        "\n",
        "# Step 7: Query the LLM\n",
        "response = query_llm(client, user_query, context)\n",
        "\n",
        "print(\"\\nResponse from the model:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e8932fc43f94dc3ab261b97ed513cdb",
            "e79c44f096b840feb4a7a4d6e160f47d",
            "f55fcc009811474caed5073ba7be725c",
            "28ede97129ba4d138350170492e19615",
            "de9eab19e5764d7c8aabc44cfec68856",
            "b0fa8bb1ac5042df936c3dfb6a9c5daa",
            "436df488e78f43739c96693af0e90ed5",
            "c6641d3a2b4044ab963bb470f190f40f",
            "8fb01a03c5324833b2479f05cef3d5a6",
            "08d3e4a1b8b74ba4aea6c54da121b3d7",
            "2f181474698841d99f64497089376523"
          ]
        },
        "id": "ePQLFbymTNdy",
        "outputId": "30fc6c37-4eb9-4ba2-8dc2-76d7eedf9ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting text from PDF...\n",
            "Splitting text into chunks...\n",
            "Tagging metadata for chunks...\n",
            "Generating embeddings for chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e8932fc43f94dc3ab261b97ed513cdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating FAISS index...\n",
            "\n",
            "Enter your query: Find details about university admissions for a candidate with the following criteria:  Z-Score: 1.7,   G.C.E. (Advanced Level) Subjects and Grades:   1. Physics - A,   2. Chemistry - A,   3. Biology - B,    Preferred Courses of Study: Medicine, Dental Surgery, Pharmacy,   District: Kandy.    List the eligible courses of study, minimum entry requirements, applicable cut-off marks\n",
            "Retrieving relevant chunks...\n",
            "Querying the LLM...\n",
            "\n",
            "Response from the model:\n",
            "Based on the provided information, here are the details about university admissions for the candidate:\n",
            "\n",
            "**Z-Score:** 1.7\n",
            "\n",
            "**G.C.E. (Advanced Level) Subjects and Grades:**\n",
            "\n",
            "1. Physics - A\n",
            "2. Chemistry - A\n",
            "3. Biology - B\n",
            "\n",
            "**Preferred Courses of Study:**\n",
            "\n",
            "1. Medicine\n",
            "2. Dental Surgery\n",
            "3. Pharmacy\n",
            "\n",
            "**District:** Kandy\n",
            "\n",
            "**Eligible Courses of Study:**\n",
            "\n",
            "Based on the Z-Score of 1.7, the candidate is eligible to apply for the following courses of study:\n",
            "\n",
            "1. Medicine\n",
            "2. Pharmacy\n",
            "\n",
            "**Minimum Entry Requirements:**\n",
            "\n",
            "For the above-mentioned courses, the minimum entry requirements are:\n",
            "\n",
            "1. Medicine: Z-Score of 1.7 or higher, with A's in Physics, Chemistry, and Biology\n",
            "2. Pharmacy: Z-Score of 1.7 or higher, with A's in Physics, Chemistry, and Biology\n",
            "\n",
            "**Applicable Cut-off Marks:**\n",
            "\n",
            "For the above-mentioned courses, the applicable cut-off marks are:\n",
            "\n",
            "1. Medicine: Not specified\n",
            "2. Pharmacy: Not specified\n",
            "\n",
            "**Note:**\n",
            "\n",
            "* The candidate has not met the minimum requirements for Dental Surgery, as the Z-Score is 1.7, which is lower than the required Z-Score for Dental Surgery.\n",
            "* The candidate may not be eligible for other courses of study that require higher Z-Scores or specific grades in certain subjects.\n",
            "* The candidate should check the university's admission requirements and cut-off marks for each course of study to confirm their eligibility.\n",
            "Saving preprocessed data...\n",
            "Data saved to processed_data.json\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import spacy\n",
        "import openai\n",
        "from groq import Groq\n",
        "import re\n",
        "import json\n",
        "\n",
        "# OpenAI API Key (Replace with your API key)\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize Groq client (Replace with your key)\n",
        "# API Key for Groq\n",
        "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "# Initialize NLP for metadata extraction\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Step 1: Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Step 2: Split text into structured chunks\n",
        "def split_text_into_chunks(text, chunk_size=300, overlap=100):\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        chunk = \" \".join(words[start:start + chunk_size])\n",
        "        chunks.append(chunk)\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "# Step 3: Extract metadata (Spacy NER)\n",
        "def tag_metadata_for_chunks(chunks):\n",
        "    print(\"Tagging metadata for chunks...\")\n",
        "    metadata = []\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        doc = nlp(chunk)\n",
        "        keywords = list(set(ent.text for ent in doc.ents))\n",
        "        metadata.append({\n",
        "            \"chunk_id\": idx,\n",
        "            \"chunk_text\": chunk,\n",
        "            \"keywords\": keywords\n",
        "        })\n",
        "    return metadata\n",
        "\n",
        "# Step 4: Generate embeddings for text chunks\n",
        "def generate_embeddings(text_chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    print(\"Generating embeddings for chunks...\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(text_chunks, show_progress_bar=True)\n",
        "    return embeddings, model\n",
        "\n",
        "# Step 5: Store embeddings in FAISS\n",
        "def create_faiss_index(embeddings):\n",
        "    print(\"Creating FAISS index...\")\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)  # L2 similarity\n",
        "    index.add(np.array(embeddings))\n",
        "    return index\n",
        "\n",
        "# Step 6: Retrieve relevant chunks using FAISS\n",
        "def retrieve_relevant_chunks(query, text_chunks, index, model, k=3):\n",
        "    print(\"Retrieving relevant chunks...\")\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(np.array(query_embedding), k=k)\n",
        "    return [text_chunks[idx] for idx in indices[0]]\n",
        "\n",
        "# Step 7: Query the language model (Groq/LLM)\n",
        "def query_llm(client, query, context):\n",
        "    print(\"Querying the LLM...\")\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant answering questions based on provided context.\"},\n",
        "        {\"role\": \"assistant\", \"content\": context},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"llama3-8b-8192\",\n",
        "        temperature=0.3,\n",
        "        max_tokens=512,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Step 8: Save processed data with metadata\n",
        "def save_preprocessed_data(chunks, metadata, embeddings, output_path=\"processed_data.json\"):\n",
        "    print(\"Saving preprocessed data...\")\n",
        "    data = [{\"chunk\": chunk, \"metadata\": meta, \"embedding\": embedding.tolist()}\n",
        "            for chunk, meta, embedding in zip(chunks, metadata, embeddings)]\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "    print(f\"Data saved to {output_path}\")\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # Input PDF Path\n",
        "    pdf_path = \"/content/drive/MyDrive/UGC.pdf\"\n",
        "\n",
        "    # Step 1: Extract text\n",
        "    document_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Step 2: Split into chunks\n",
        "    text_chunks = split_text_into_chunks(document_text, chunk_size=300, overlap=100)\n",
        "\n",
        "    # Step 3: Tag metadata\n",
        "    metadata = tag_metadata_for_chunks(text_chunks)\n",
        "\n",
        "    # Step 4: Generate embeddings\n",
        "    embeddings, embedding_model = generate_embeddings([meta['chunk_text'] for meta in metadata])\n",
        "\n",
        "    # Step 5: Create FAISS index\n",
        "    faiss_index = create_faiss_index(embeddings)\n",
        "\n",
        "    # Step 6: User Query\n",
        "    user_query = input(\"\\nEnter your query: \")\n",
        "\n",
        "    # Step 7: Retrieve relevant chunks\n",
        "    relevant_chunks = retrieve_relevant_chunks(user_query, [meta['chunk_text'] for meta in metadata], faiss_index, embedding_model)\n",
        "    context = \" \".join(relevant_chunks)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Details by each chunk- not important for now\n",
        "    # print(\"\\nRelevant Chunks:\")\n",
        "    # for idx, chunk in enumerate(relevant_chunks):\n",
        "    #     print(f\"\\nChunk {idx + 1}:\\n{chunk}\")\n",
        "\n",
        "    # Step 8: Query LLM\n",
        "    llm_response = query_llm(client, user_query, context)\n",
        "    print(\"\\nResponse from the model:\")\n",
        "    print(llm_response)\n",
        "\n",
        "    # Step 9: Save processed data\n",
        "    save_preprocessed_data([meta['chunk_text'] for meta in metadata], metadata, embeddings)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08d3e4a1b8b74ba4aea6c54da121b3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ede97129ba4d138350170492e19615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d3e4a1b8b74ba4aea6c54da121b3d7",
            "placeholder": "​",
            "style": "IPY_MODEL_2f181474698841d99f64497089376523",
            "value": " 11/11 [00:43&lt;00:00,  2.99s/it]"
          }
        },
        "2f181474698841d99f64497089376523": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "436df488e78f43739c96693af0e90ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e8932fc43f94dc3ab261b97ed513cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e79c44f096b840feb4a7a4d6e160f47d",
              "IPY_MODEL_f55fcc009811474caed5073ba7be725c",
              "IPY_MODEL_28ede97129ba4d138350170492e19615"
            ],
            "layout": "IPY_MODEL_de9eab19e5764d7c8aabc44cfec68856"
          }
        },
        "8fb01a03c5324833b2479f05cef3d5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0fa8bb1ac5042df936c3dfb6a9c5daa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6641d3a2b4044ab963bb470f190f40f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9eab19e5764d7c8aabc44cfec68856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79c44f096b840feb4a7a4d6e160f47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0fa8bb1ac5042df936c3dfb6a9c5daa",
            "placeholder": "​",
            "style": "IPY_MODEL_436df488e78f43739c96693af0e90ed5",
            "value": "Batches: 100%"
          }
        },
        "f55fcc009811474caed5073ba7be725c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6641d3a2b4044ab963bb470f190f40f",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fb01a03c5324833b2479f05cef3d5a6",
            "value": 11
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
